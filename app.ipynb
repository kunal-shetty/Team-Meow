{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfiy15Ul+valzbGyZ4I8/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunal-shetty/Chest-X-ray-disease-prediction/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "!ls /content/drive/MyDrive/Colab\\ Notebooks/real\\ data\n"
      ],
      "metadata": {
        "id": "rvpRg1EnBDBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/real data/\"\n",
        "\n",
        "bbox = pd.read_csv(BASE_PATH + \"bbox_2.csv\")\n",
        "data = pd.read_csv(BASE_PATH + \"data_entry.csv\")\n",
        "\n",
        "corrupt_bbox = pd.read_csv(BASE_PATH + \"HACKATHON_CORRUPTED_BBox_List.csv\")\n",
        "corrupt_data = pd.read_csv(BASE_PATH + \"HACKATHON_CORRUPTED_Data_Entry.csv\")\n"
      ],
      "metadata": {
        "id": "C6DTVRwUYIQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/real data/HACKATHON_CORRUPTED_Data_Entry.csv\"\n",
        ")\n",
        "\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "error_log = []\n",
        "\n",
        "def normalize_image_index(idx):\n",
        "    idx = str(idx).strip()\n",
        "    match = re.match(r\"^(\\d+)_([0-9]{3})\\.png$\", idx)\n",
        "    if match:\n",
        "        patient_id, img_no = match.groups()\n",
        "        return f\"{patient_id.zfill(8)}_{img_no}.png\"\n",
        "    return idx  # already correct or unknown format\n",
        "\n"
      ],
      "metadata": {
        "id": "_EmZaZoSfAsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract digits only (058Y → 58, -5 → 5, ?? → NaN)\n",
        "age_extracted = data[\"patient_age\"].astype(str).str.extract(r\"(\\d+)\", expand=False)\n",
        "\n",
        "data[\"patient_age\"] = pd.to_numeric(age_extracted, errors=\"coerce\")\n",
        "\n",
        "# mark invalid ages\n",
        "invalid_age_mask = (\n",
        "    data[\"patient_age\"].isna() |\n",
        "    (data[\"patient_age\"] <= 1) |\n",
        "    (data[\"patient_age\"] > 100)\n",
        ")\n",
        "\n",
        "# log errors\n",
        "age_errors = data[invalid_age_mask].copy()\n",
        "age_errors[\"error_reason\"] = \"INVALID_PATIENT_AGE\"\n",
        "age_errors[\"error_column\"] = \"patient_age\"\n",
        "age_errors[\"logged_at\"] = timestamp\n",
        "\n",
        "error_log.append(age_errors)\n",
        "\n"
      ],
      "metadata": {
        "id": "6hsgqszbmiwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_views = [\"PA\", \"AP\", \"LATERAL\"]\n",
        "\n",
        "data[\"View Position\"] = data[\"View Position\"].where(\n",
        "    data[\"View Position\"].isin(valid_views),\n",
        "    \"UNKNOWN\"\n",
        ")\n",
        "\n",
        "invalid_view_mask = data[\"View Position\"] == \"UNKNOWN\"\n",
        "\n",
        "view_errors = data[invalid_view_mask].copy()\n",
        "view_errors[\"error_reason\"] = \"INVALID_VIEW_POSITION\"\n",
        "view_errors[\"error_column\"] = \"View Position\"\n",
        "view_errors[\"logged_at\"] = timestamp\n",
        "\n",
        "error_log.append(view_errors)\n"
      ],
      "metadata": {
        "id": "QuAzIRo5mqkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_finding_labels(label):\n",
        "    if pd.isna(label):\n",
        "        return \"UNKNOWN_LABEL\"\n",
        "\n",
        "    parts = str(label).split(\"|\")\n",
        "    cleaned = []\n",
        "\n",
        "    for p in parts:\n",
        "        p = p.strip()\n",
        "        if p in VALID_FINDINGS:\n",
        "            cleaned.append(p)\n",
        "\n",
        "    if not cleaned:\n",
        "        return \"UNKNOWN_LABEL\"\n",
        "\n",
        "    # sort for consistency\n",
        "    return \"|\".join(sorted(set(cleaned)))\n",
        "\n",
        "\n",
        "VALID_FINDINGS = {\n",
        "    \"Atelectasis\",\n",
        "    \"Cardiomegaly\",\n",
        "    \"Effusion\",\n",
        "    \"Infiltration\",\n",
        "    \"Mass\",\n",
        "    \"Nodule\",\n",
        "    \"Pneumonia\",\n",
        "    \"Pneumothorax\",\n",
        "    \"Emphysema\",\n",
        "    \"Fibrosis\",\n",
        "    \"Pleural_Thickening\",\n",
        "    \"Hernia\",\n",
        "    \"No Finding\"\n",
        "}\n",
        "\n",
        "original_labels = data[\"finding_labels\"].copy()\n",
        "\n",
        "data[\"finding_labels\"] = data[\"finding_labels\"].apply(clean_finding_labels)\n",
        "\n",
        "label_changed_mask = original_labels != data[\"finding_labels\"]\n",
        "\n",
        "label_errors = data[label_changed_mask].copy()\n",
        "label_errors[\"error_reason\"] = \"INVALID_OR_OUTLIER_FINDING_LABEL\"\n",
        "label_errors[\"error_column\"] = \"finding_labels\"\n",
        "label_errors[\"logged_at\"] = timestamp\n",
        "\n",
        "error_log.append(label_errors)\n"
      ],
      "metadata": {
        "id": "RL62hIfI5BMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Gender IN-PLACE (canonical: M, F, UNKNOWN)\n",
        "data[\"Gender\"] = (\n",
        "    data[\"Gender\"]\n",
        "    .replace([pd.NA, None], \"UNKNOWN\")\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        ")\n",
        "\n",
        "# Map textual values to canonical form\n",
        "gender_map = {\n",
        "    \"m\": \"M\",\n",
        "    \"male\": \"M\",\n",
        "    \"f\": \"F\",\n",
        "    \"female\": \"F\"\n",
        "}\n",
        "\n",
        "data[\"Gender\"] = data[\"Gender\"].map(gender_map).fillna(\"UNKNOWN\")\n",
        "\n",
        "# Log rows that were UNKNOWN\n",
        "invalid_gender_mask = data[\"Gender\"] == \"UNKNOWN\"\n",
        "\n",
        "gender_errors = data[invalid_gender_mask].copy()\n",
        "gender_errors[\"error_reason\"] = \"INVALID_OR_MISSING_GENDER\"\n",
        "gender_errors[\"error_column\"] = \"Gender\"\n",
        "gender_errors[\"logged_at\"] = timestamp\n",
        "\n",
        "error_log.append(gender_errors)\n"
      ],
      "metadata": {
        "id": "k12tLL_3msv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Temp_Notes\"] = (\n",
        "    data[\"Temp_Notes\"]\n",
        "    .replace([pd.NA, None], \"N/A\")     # real NaNs first\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .replace([\"\", \"nan\", \"NaN\", \"NA\"], \"N/A\")\n",
        ")\n",
        "\n",
        "# Log rows that were normalized\n",
        "notes_errors = data[data[\"Temp_Notes\"] == \"N/A\"].copy()\n",
        "notes_errors[\"error_reason\"] = \"PLACEHOLDER_TEMP_NOTES\"\n",
        "notes_errors[\"error_column\"] = \"Temp_Notes\"\n",
        "notes_errors[\"logged_at\"] = timestamp\n",
        "\n",
        "error_log.append(notes_errors)\n"
      ],
      "metadata": {
        "id": "vsDl5Xrsm6ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect rows that need normalization\n",
        "image_fix_mask = data[\"Image Index\"].astype(str).str.match(r\"^\\d{1,7}_\\d{3}\\.png$\")\n",
        "\n",
        "# log BEFORE fixing\n",
        "image_fix_errors = data[image_fix_mask].copy()\n",
        "image_fix_errors[\"error_reason\"] = \"IMAGE_INDEX_NORMALIZED\"\n",
        "image_fix_errors[\"error_column\"] = \"Image Index\"\n",
        "image_fix_errors[\"logged_at\"] = timestamp\n",
        "\n",
        "error_log.append(image_fix_errors)\n",
        "\n",
        "# FIX IN-PLACE\n",
        "data.loc[image_fix_mask, \"Image Index\"] = (\n",
        "    data.loc[image_fix_mask, \"Image Index\"]\n",
        "    .apply(normalize_image_index)\n",
        ")\n"
      ],
      "metadata": {
        "id": "1ZimZgFxm9KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "UNKNOWN_VALUES = [\"UNKNOWN\", \"UNKNOWN_IMAGE\", \"N/A\", \"UNKNOWN\",\"UNKNOWN_LABEL\", \"invalid_image.png\"]\n",
        "\n",
        "delete_mask = (\n",
        "    invalid_age_mask |\n",
        "    data[\"Gender\"].isin(UNKNOWN_VALUES) |\n",
        "    data[\"View Position\"].isin(UNKNOWN_VALUES) |\n",
        "    data[\"Image Index\"].isin(UNKNOWN_VALUES) |\n",
        "    data[\"finding_labels\"].isin(UNKNOWN_VALUES)\n",
        ")\n",
        "\n",
        "rows_before = len(data)\n",
        "\n",
        "data = data[~delete_mask].reset_index(drop=True)\n",
        "\n",
        "rows_after = len(data)\n",
        "\n",
        "print(f\"Deleted {rows_before - rows_after} rows containing UNKNOWN / invalid values\")\n"
      ],
      "metadata": {
        "id": "gM83UtX72xS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_log_df = pd.concat(error_log, ignore_index=True)\n",
        "\n",
        "final_error_log = (\n",
        "    error_log_df\n",
        "    .groupby(\"Image Index\", as_index=False)\n",
        "    .agg({\n",
        "        **{col: \"first\" for col in error_log_df.columns if col != \"error_reason\"},\n",
        "        \"error_reason\": lambda x: \"; \".join(sorted(set(x)))\n",
        "    })\n",
        ")\n",
        "\n",
        "# Define key columns to KEEP\n",
        "KEY_COLUMNS = [\n",
        "    \"Image Index\",\n",
        "    \"Patient ID\",\n",
        "    \"Gender\",\n",
        "    \"patient_age\",\n",
        "    \"View Position\",\n",
        "    \"finding_labels\",\n",
        "    \"OriginalImageWidth\",\n",
        "    \"OriginalImageHeight\",\n",
        "    \"OriginalImagePixelSpacing_x\",\n",
        "    \"OriginalImagePixelSpacing_y\"\n",
        "]\n",
        "\n",
        "# Keep only key columns\n",
        "final_model_data = data[KEY_COLUMNS].copy()\n",
        "\n",
        "# Save final dataset\n",
        "final_model_data.to_csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/outputs/FINAL_clean_data.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "final_error_log.to_csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/outputs/ERROR_LOG_clean_data.csv\",\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "if1dVMBKpuY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uutaZcpEtTPF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebook/real data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile  # This line fixes the NameError\n",
        "import os\n",
        "\n",
        "existing_images = set()\n",
        "zip_files = [f for f in os.listdir(BASE_PATH) if f.endswith('.zip')]\n",
        "\n",
        "for zip_file in zip_files:\n",
        "    with zipfile.ZipFile(os.path.join(BASE_PATH, zip_file), 'r') as z:\n",
        "        # Get list of files, filtering for only .png or .jpg\n",
        "        contents = [f for f in z.namelist() if f.lower().endswith(('.png', '.jpg'))]\n",
        "        # Store only the filename, not the path\n",
        "        existing_images.update([os.path.basename(f) for f in contents])\n",
        "\n",
        "print(f\"Inventory Restored: {len(existing_images)} images found.\")"
      ],
      "metadata": {
        "id": "pf7BUMahtsag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the BBox Audit Log to identify \"Ghost Images\" (missing files) and \"Geometric Anomalies\" (bad coordinates).\n",
        "## Fix: Load the data into the 'bbox' variable first\n",
        "bbox = pd.read_csv(BASE_PATH + \"bbox_2.csv\")\n",
        "\n",
        "# 1. Identify 'Ghost Images'\n",
        "csv_images = set(bbox['Image Index'].unique())\n",
        "ghost_images = csv_images - existing_images\n",
        "\n",
        "ghost_errors = bbox[bbox['Image Index'].isin(ghost_images)].copy()\n",
        "ghost_errors['error_reason'] = \"IMAGE_FILE_NOT_FOUND_IN_REPOSITORY\"\n",
        "\n",
        "# 2. Identify Geometric Anomalies\n",
        "# Using 'bbox-y' as identified in your earlier data preview\n",
        "neg_mask = (bbox['bbox_x'] < 0) | (bbox['bbox-y'] < 0) | (bbox['width'] < 0) | (bbox['height'] < 0)\n",
        "neg_errors = bbox[neg_mask].copy()\n",
        "neg_errors['error_reason'] = \"NEGATIVE_COORDINATES\"\n",
        "\n",
        "# Check for boxes that extend outside the 1024x1024 clinical boundaries\n",
        "oob_mask = (\n",
        "    (bbox['bbox_x'] + bbox['width'] > 1024) |\n",
        "    (bbox['bbox-y'] + bbox['height'] > 1024)\n",
        ")\n",
        "oob_errors = bbox[oob_mask].copy()\n",
        "oob_errors['error_reason'] = \"COORDINATES_OUT_OF_BOUNDS_1024\"\n",
        "\n",
        "# 3. Combine your findings\n",
        "my_error_log = pd.concat([ghost_errors, neg_errors, oob_errors], ignore_index=True)\n",
        "\n",
        "print(f\"BBox variable defined and Audit Complete!\")\n",
        "print(f\"Found {len(my_error_log)} total anomalies.\")"
      ],
      "metadata": {
        "id": "3TD66a3duzTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a Standardized Clean Dataset (the good data) and an Error Log (the bad data) to satisfy the Code-Only Workflow audit requirements.\n",
        "# 1. Create a unique identifier for the errors we found\n",
        "my_error_log['uid'] = my_error_log['Image Index'] + my_error_log['Finding Label']\n",
        "bbox['uid'] = bbox['Image Index'] + bbox['Finding Label']\n",
        "\n",
        "# 2. Filter: Keep only rows that are NOT in our error list\n",
        "clean_bbox = bbox[~bbox['uid'].isin(my_error_log['uid'])].copy()\n",
        "\n",
        "# 3. Clean up the temporary column\n",
        "clean_bbox = clean_bbox.drop(columns=['uid'])\n",
        "\n",
        "# 4. Save again\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Colab Notebooks/outputs/\"\n",
        "clean_bbox.to_csv(OUTPUT_PATH + \"CLEAN_BBOX_DATA.csv\", index=False)\n",
        "\n",
        "print(f\"Error Resolved!\")\n",
        "print(f\"Total rows in original: {len(bbox)}\")\n",
        "print(f\"Total rows in clean: {len(clean_bbox)}\")"
      ],
      "metadata": {
        "id": "ulgvlCfdveQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Let's see which file actually has the bulk of the data\n",
        "files = [\"bbox_2.csv\", \"HACKATHON_CORRUPTED_BBox_List.csv\"]\n",
        "for f in files:\n",
        "    temp_df = pd.read_csv(BASE_PATH + f)\n",
        "    print(f\"{f} contains {len(temp_df)} rows.\")\n"
      ],
      "metadata": {
        "id": "rkiv-Q7lwEiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Inspect the actual column names in the corrupted file\n",
        "print(\"Actual columns in file:\", full_bbox.columns.tolist())\n",
        "\n",
        "# 2. Clean the column names (remove hidden spaces)\n",
        "full_bbox.columns = full_bbox.columns.str.strip()\n",
        "\n",
        "# 3. Check if 'bbox_x' exists after stripping, if not, find the close match\n",
        "# Based on your previous data, it might be 'Bbox_x' or 'bbox-x'\n",
        "print(\"Cleaned columns:\", full_bbox.columns.tolist())"
      ],
      "metadata": {
        "id": "PrEDCIehwXgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. We use the 'full_bbox' variable you just cleaned\n",
        "# (Already cleaned via .str.strip() in your previous step)\n",
        "\n",
        "# 2. Programmatic Cleansing Logic\n",
        "# Identify Missing Files (Ghost Images)\n",
        "ghost_mask = ~full_bbox['Image Index'].isin(existing_images)\n",
        "\n",
        "# Identify Geometric Anomalies (Using corrected names 'bbox_x' and 'bbox-y')\n",
        "neg_mask = (full_bbox['bbox_x'] < 0) | (full_bbox['bbox-y'] < 0) | (full_bbox['width'] < 0) | (full_bbox['height'] < 0)\n",
        "oob_mask = (full_bbox['bbox_x'] + full_bbox['width'] > 1024) | (full_bbox['bbox-y'] + full_bbox['height'] > 1024)\n",
        "\n",
        "# 3. Create the Audit Trail (Error Log)\n",
        "full_error_log = full_bbox[ghost_mask | neg_mask | oob_mask].copy()\n",
        "full_error_log['error_reason'] = \"DATA_CORRUPTION_OR_MISSING_IMAGE\"\n",
        "\n",
        "# 4. Create the Standardized Clean Dataset\n",
        "clean_bbox_final = full_bbox[~(ghost_mask | neg_mask | oob_mask)].copy()\n",
        "\n",
        "# 5. Save the final results to your outputs folder\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Colab Notebooks/outputs/\"\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "clean_bbox_final.to_csv(OUTPUT_PATH + \"FINAL_CLEAN_BBOX_LIST.csv\", index=False)\n",
        "full_error_log.to_csv(OUTPUT_PATH + \"BBOX_AUDIT_REPORT.csv\", index=False)\n",
        "\n",
        "print(f\"Round 1: Sanitization Successful!\")\n",
        "print(f\"Cleaned Records: {len(clean_bbox_final)}\")\n",
        "print(f\"Flagged Anomalies: {len(full_error_log)}\")"
      ],
      "metadata": {
        "id": "Y9_g3XHnw3hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "analysis_data = pd.read_csv(BASE_PATH + \"FINAL_clean_data.csv\")\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/outputs/\"\n",
        "\n",
        "print(\"Rows:\", analysis_data.shape[0])\n",
        "print(\"Columns:\", analysis_data.shape[1])\n",
        "\n",
        "analysis_data = analysis_data.copy()\n"
      ],
      "metadata": {
        "id": "i3fQOCVFBuI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_data[\"Case\"] = analysis_data[\"finding_labels\"].apply(\n",
        "    lambda x: \"Normal\" if x == \"No Finding\" else \"Abnormal\"\n",
        ")\n",
        "\n",
        "normal_abnormal_counts = analysis_data[\"Case\"].value_counts()\n",
        "print(normal_abnormal_counts)\n",
        "\n",
        "normal_abnormal_counts.plot(\n",
        "    kind=\"bar\",\n",
        "    color=[\"green\", \"red\"],\n",
        "    title=\"Normal vs Abnormal Cases\"\n",
        ")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6Mxn3CAWFAPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_abnormal_counts.plot(\n",
        "    kind=\"pie\",\n",
        "    autopct=\"%1.1f%%\",\n",
        "    startangle=90,\n",
        "    colors=[\"green\", \"red\"]\n",
        ")\n",
        "plt.ylabel(\"\")\n",
        "plt.title(\"Normal vs Abnormal Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAA0jipVGxcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = (\n",
        "    analysis_data[\"finding_labels\"]\n",
        "    .str.split(\"|\")\n",
        "    .explode()\n",
        ")\n",
        "\n",
        "label_frequency = all_labels.value_counts()\n",
        "print(label_frequency)\n",
        "\n",
        "label_frequency.plot(kind=\"bar\", figsize=(10,5))\n",
        "plt.title(\"Frequency of Each Disease Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xlabel(\"Diseases\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7MZ-3rK-G01F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_data[\"num_labels\"] = analysis_data[\"finding_labels\"].apply(\n",
        "    lambda x: len(x.split(\"|\"))\n",
        ")\n",
        "\n",
        "multi_diag_percentage = (analysis_data[\"num_labels\"] > 1).mean() * 100\n",
        "print(f\"Patients with multiple diagnoses: {multi_diag_percentage:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xeB6EgQZG4-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_per_patient = analysis_data.groupby(\"Patient ID\")[\"Image Index\"].count()\n",
        "\n",
        "images_per_patient.value_counts().sort_index().plot(kind=\"bar\")\n",
        "plt.title(\"Number of Images per Patient\")\n",
        "plt.xlabel(\"Images per Patient\")\n",
        "plt.ylabel(\"Number of Patients\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "syH5WIaJG7io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "label_matrix = mlb.fit_transform(\n",
        "    analysis_data[\"finding_labels\"].str.split(\"|\")\n",
        ")\n",
        "\n",
        "label_df = pd.DataFrame(label_matrix, columns=mlb.classes_)\n",
        "label_corr = label_df.corr()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(label_corr, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Heatmap of Diagnostic Label Correlations\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iKX2MWX6HBFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "metadata": {
        "id": "V-rJcogqT62N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/drive/MyDrive/Colab Notebooks/outputs/FINAL_clean_data.csv\"\n",
        "IMAGE_ROOT = \"/content/drive/MyDrive/Colab Notebooks/real data/images_0013/images\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# split labels\n",
        "df[\"finding_labels\"] = df[\"finding_labels\"].apply(lambda x: x.split(\"|\"))\n",
        "\n",
        "# build image paths\n",
        "df[\"image_path\"] = df[\"Image Index\"].astype(str).apply(\n",
        "    lambda x: os.path.join(IMAGE_ROOT, x)\n",
        ")\n",
        "\n",
        "df[\"image_exists\"] = df[\"image_path\"].apply(os.path.exists)\n",
        "df = df[df[\"image_exists\"]].reset_index(drop=True)\n",
        "\n",
        "print(\"Images that exist:\", len(df))\n"
      ],
      "metadata": {
        "id": "9XtQFI_tT9D_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(df[\"finding_labels\"])\n",
        "\n",
        "NUM_CLASSES = len(mlb.classes_)\n",
        "print(\"Number of disease labels:\", NUM_CLASSES)\n"
      ],
      "metadata": {
        "id": "vHCekYvZbwss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
        "\n",
        "train_idx, test_idx = next(\n",
        "    gss.split(df, Y, groups=df[\"Patient ID\"])\n",
        ")\n",
        "\n",
        "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "test_df  = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "Y_train = Y[train_idx]\n",
        "Y_test  = Y[test_idx]\n",
        "\n",
        "print(\"Train:\", len(train_df))\n",
        "print(\"Test:\", len(test_df))\n"
      ],
      "metadata": {
        "id": "LZTvprTygslH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "VNOFhQWDbyYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train_mem = [], []\n",
        "X_test,  Y_test_mem  = [], []\n",
        "\n",
        "print(\"Loading TRAIN images into memory...\")\n",
        "for i in tqdm(range(len(train_df))):\n",
        "    try:\n",
        "        img = Image.open(train_df.loc[i, \"image_path\"]).convert(\"RGB\")\n",
        "        img = transform(img)\n",
        "        X_train.append(img)\n",
        "        Y_train_mem.append(torch.tensor(Y_train[i], dtype=torch.float32))\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Loading TEST images into memory...\")\n",
        "for i in tqdm(range(len(test_df))):\n",
        "    try:\n",
        "        img = Image.open(test_df.loc[i, \"image_path\"]).convert(\"RGB\")\n",
        "        img = transform(img)\n",
        "        X_test.append(img)\n",
        "        Y_test_mem.append(torch.tensor(Y_test[i], dtype=torch.float32))\n",
        "    except:\n",
        "        continue\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k57ymPpvbz4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.stack(X_train)\n",
        "Y_train_mem = torch.stack(Y_train_mem)\n",
        "\n",
        "X_test = torch.stack(X_test)\n",
        "Y_test_mem = torch.stack(Y_test_mem)\n",
        "\n",
        "print(\"Final train samples:\", X_train.shape[0])\n",
        "print(\"Final test samples:\", X_test.shape[0])\n"
      ],
      "metadata": {
        "id": "EUuuWZpzb1sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train, Y_train_mem),\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(X_test, Y_test_mem),\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "WtUzMGvmb3Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "2puINKZwb4lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for imgs, labels in tqdm(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dxJmVnHNb51-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "        preds.append(outputs)\n",
        "        targets.append(labels.numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "targets = np.vstack(targets)\n",
        "\n",
        "auc = roc_auc_score(targets, preds, average=\"micro\")\n",
        "print(\"TRAIN MICRO-AUROC:\", auc)"
      ],
      "metadata": {
        "id": "2z1lziU5iKe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"label_names\": mlb.classes_\n",
        "}, \"xray_multilabel_model.pth\")\n"
      ],
      "metadata": {
        "id": "DvEVxB32t60J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\n",
        "    \"xray_multilabel_model.pth\",\n",
        "    map_location=device,\n",
        "    weights_only=False\n",
        ")\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(checkpoint[\"label_names\"]))\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "label_names = checkpoint[\"label_names\"]\n"
      ],
      "metadata": {
        "id": "b5sZOcoeuGIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_xray(image_path, threshold=0.5):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)  # add batch dim\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    results = {\n",
        "        label_names[i]: float(probs[i])\n",
        "        for i in range(len(label_names))\n",
        "        if probs[i] >= threshold\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "hzi-mTDiuJC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_predict(indices, threshold=0.5):\n",
        "    imgs = torch.stack([X_train[i] for i in indices]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "\n",
        "    for k, idx in enumerate(indices):\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Image index: {idx}\")\n",
        "\n",
        "        age = train_df.loc[idx, \"patient_age\"] if \"patient_age\" in train_df.columns else \"NA\"\n",
        "        gender = train_df.loc[idx, \"gender\"] if \"gender\" in train_df.columns else \"NA\"\n",
        "        view = train_df.loc[idx, \"view_position\"] if \"view_position\" in train_df.columns else \"NA\"\n",
        "\n",
        "        print(f\"Age: {age}, Gender: {gender}, View: {view}\")\n",
        "        print(\"Detected findings:\")\n",
        "\n",
        "        found = False\n",
        "        for i, p in enumerate(probs[k]):\n",
        "            if p >= threshold:\n",
        "                print(f\"• {label_names[i]} → {p:.3f}\")\n",
        "                found = True\n",
        "\n",
        "        if not found:\n",
        "            print(\"• Normal\")\n"
      ],
      "metadata": {
        "id": "AcAo3bw9uXxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_raw(idx):\n",
        "    img = X_train[idx].unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    print(f\"\\nRAW probabilities for image index {idx}:\")\n",
        "    for i, p in enumerate(probs):\n",
        "        print(f\"{label_names[i]:25s} : {p:.4f}\")\n"
      ],
      "metadata": {
        "id": "BUU0kjJMwwXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STEP 1: Get predictions on training data\n",
        "# --------------------------------------------------\n",
        "\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in DataLoader(\n",
        "        TensorDataset(X_train, Y_train_mem),\n",
        "        batch_size=16,\n",
        "        shuffle=False\n",
        "    ):\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "        preds.append(outputs)\n",
        "        targets.append(labels.numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "targets = np.vstack(targets)\n",
        "\n",
        "print(\"Predictions shape:\", preds.shape)\n",
        "print(\"Targets shape:\", targets.shape)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STEP 2: Plot ROC curves for ALL diseases\n",
        "# --------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "valid_disease_count = 0\n",
        "auc_scores = {}\n",
        "\n",
        "for i, disease in enumerate(label_names):\n",
        "\n",
        "    # AUROC undefined if only one class present\n",
        "    if len(np.unique(targets[:, i])) < 2:\n",
        "        auc_scores[disease] = None\n",
        "        continue\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(targets[:, i], preds[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(\n",
        "        fpr,\n",
        "        tpr,\n",
        "        lw=1.5,\n",
        "        label=f\"{disease} (AUC={roc_auc:.2f})\"\n",
        "    )\n",
        "\n",
        "    auc_scores[disease] = roc_auc\n",
        "    valid_disease_count += 1\n",
        "\n",
        "# Diagonal reference line\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(f\"ROC Curves for All Diseases (Valid = {valid_disease_count})\")\n",
        "plt.legend(fontsize=8, loc=\"lower right\", ncol=2)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------------------\n",
        "# STEP 3: Print per-disease AUROC table\n",
        "# --------------------------------------------------\n",
        "\n",
        "print(\"\\nPer-Disease AUROC Summary\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for disease, score in auc_scores.items():\n",
        "    if score is None:\n",
        "        print(f\"{disease:25s} : N/A (single class)\")\n",
        "    else:\n",
        "        print(f\"{disease:25s} : {score:.3f}\")\n"
      ],
      "metadata": {
        "id": "4Nxe-ifFw3AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gradcam_generate(model, img, target_class, target_layer):\n",
        "    \"\"\"\n",
        "    Hook-free Grad-CAM implementation\n",
        "    \"\"\"\n",
        "    activations = None\n",
        "    gradients = None\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        nonlocal activations\n",
        "        activations = output\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        nonlocal gradients\n",
        "        gradients = grad_out[0]\n",
        "\n",
        "    # Register hooks TEMPORARILY\n",
        "    fh = target_layer.register_forward_hook(forward_hook)\n",
        "    bh = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward + backward\n",
        "    model.zero_grad()\n",
        "    output = model(img)\n",
        "    score = output[0, target_class]\n",
        "    score.backward()\n",
        "\n",
        "    # Compute Grad-CAM\n",
        "    weights = gradients.mean(dim=(2, 3), keepdim=True)\n",
        "    cam = (weights * activations).sum(dim=1)\n",
        "    cam = F.relu(cam)\n",
        "    cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "    # Remove hooks immediately (IMPORTANT)\n",
        "    fh.remove()\n",
        "    bh.remove()\n",
        "\n",
        "    return cam[0].detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "hz5A-IRSxvCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in DataLoader(\n",
        "        TensorDataset(X_train, Y_train_mem),\n",
        "        batch_size=16,\n",
        "        shuffle=False\n",
        "    ):\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
        "        preds.append(outputs)\n",
        "        targets.append(labels.numpy())\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "targets = np.vstack(targets)\n"
      ],
      "metadata": {
        "id": "OS3CyBtr3qcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "infer_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "zfS4l-Pv83yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def safe_load_image(path):\n",
        "    try:\n",
        "        # OpenCV read (much more stable with Drive)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            raise ValueError(\"cv2.imread failed\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Skipping image due to read error: {path}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Ruv3bL669cCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(50):\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Image index: {idx}\")\n",
        "\n",
        "    age = train_df.loc[idx, \"patient_age\"] if \"patient_age\" in train_df.columns else \"NA\"\n",
        "    gender = train_df.loc[idx, \"gender\"] if \"gender\" in train_df.columns else \"NA\"\n",
        "    view = train_df.loc[idx, \"view_position\"] if \"view_position\" in train_df.columns else \"NA\"\n",
        "\n",
        "    print(f\"Patient Age : {age}\")\n",
        "    print(f\"Gender      : {gender}\")\n",
        "    print(f\"View        : {view}\")\n",
        "\n",
        "    img = X_train[idx].unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(img)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    print(\"\\nRaw Output Probabilities (%):\")\n",
        "    for i, p in enumerate(probs):\n",
        "        print(f\"{label_names[i]:25s} : {p*100:.2f}%\")\n",
        "\n",
        "    detected = [(i, p) for i, p in enumerate(probs) if p >= 0.3]\n",
        "\n",
        "    print(\"\\nDetected Findings (threshold = 30%):\")\n",
        "    if not detected:\n",
        "        print(\"• Normal (no abnormal findings)\")\n",
        "        continue\n",
        "\n",
        "    for i, p in detected:\n",
        "        print(f\"• {label_names[i]} → {p*100:.2f}%\")\n",
        "\n",
        "    top_class = max(detected, key=lambda x: x[1])[0]\n",
        "\n",
        "    # ---- Grad-CAM for TOP prediction ----\n",
        "    top_class = max(detected, key=lambda x: x[1])[0]\n",
        "\n",
        "    cam = gradcam_generate(model=model, img=img, target_class=top_class, target_layer=model.layer4)\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "    original = X_train[idx].permute(1, 2, 0).cpu().numpy()\n",
        "    original = (original - original.min()) / (original.max() - original.min() + 1e-8)\n",
        "\n",
        "    overlay = 0.6 * original + 0.4 * heatmap / 255.0\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(f\"Grad-CAM → {label_names[top_class]}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XWISLx9JuMXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For user input images\n",
        "\n",
        "# user_images = [\n",
        "#     \"/content/drive/MyDrive/Colab Notebooks/real data/images_0013/images/00003929_000.png\"\n",
        "# ]\n",
        "\n",
        "# for idx, img_path in enumerate(user_images):\n",
        "\n",
        "#     print(\"=\" * 70)\n",
        "#     print(f\"User Image {idx+1}: {img_path}\")\n",
        "\n",
        "#     # ---- Load image ----\n",
        "#     img_pil = safe_load_image(img_path)\n",
        "#     if img_pil is None:\n",
        "#       continue  # skip this image safely\n",
        "\n",
        "#     img_tensor = infer_transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "#     # ---- Inference ----\n",
        "#     with torch.no_grad():\n",
        "#         logits = model(img_tensor)\n",
        "#         probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "#     # ---- Raw probabilities ----\n",
        "#     print(\"\\nRaw Output Probabilities (%):\")\n",
        "#     for i, p in enumerate(probs):\n",
        "#         print(f\"{label_names[i]:25s} : {p*100:.2f}%\")\n",
        "\n",
        "#     # ---- Thresholding ----\n",
        "#     detected = [(i, p) for i, p in enumerate(probs) if p >= 0.3]\n",
        "\n",
        "#     print(\"\\nDetected Findings (threshold = 30%):\")\n",
        "#     if not detected:\n",
        "#         print(\"• Normal (no abnormal findings)\")\n",
        "#         continue\n",
        "\n",
        "#     for i, p in detected:\n",
        "#         print(f\"• {label_names[i]} → {p*100:.2f}%\")\n",
        "\n",
        "#     # ---- Grad-CAM only if abnormal ----\n",
        "#     top_class = max(detected, key=lambda x: x[1])[0]\n",
        "\n",
        "#     cam = gradcam_generate(\n",
        "#         model=model,\n",
        "#         img=img_tensor,\n",
        "#         target_class=top_class,\n",
        "#         target_layer=model.layer4\n",
        "#     )\n",
        "\n",
        "#     # ---- Reddish-brown overlay ----\n",
        "#     cam = cam - cam.min()\n",
        "#     cam = cam / (cam.max() + 1e-8)\n",
        "#     cam = cv2.resize(cam, (224, 224))\n",
        "\n",
        "#     CAM_THRESHOLD = 0.4\n",
        "#     cam_mask = cam > CAM_THRESHOLD\n",
        "\n",
        "#     original = np.array(img_pil.resize((224, 224))) / 255.0\n",
        "\n",
        "#     brown_overlay = np.zeros_like(original)\n",
        "#     brown_overlay[..., 0] = cam * 0.9\n",
        "#     brown_overlay[..., 1] = cam * 0.35\n",
        "#     brown_overlay[..., 2] = cam * 0.15\n",
        "\n",
        "#     overlay = original.copy()\n",
        "#     overlay[cam_mask] = (\n",
        "#         0.65 * original[cam_mask] +\n",
        "#         0.35 * brown_overlay[cam_mask]\n",
        "#     )\n",
        "\n",
        "#     plt.figure(figsize=(4, 4))\n",
        "#     plt.imshow(overlay)\n",
        "#     plt.title(f\"Grad-CAM → {label_names[top_class]}\")\n",
        "#     plt.axis(\"off\")\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "j1t3KRIB9x-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}